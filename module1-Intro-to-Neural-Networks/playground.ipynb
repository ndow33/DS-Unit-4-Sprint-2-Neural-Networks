{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer: \n",
    "This is the data that is received by the neural network. It is the only layer that interacts directly with the initial data.\n",
    "\n",
    "### Hidden Layer: \n",
    "This is the \"black box\" of the neural network. The hidden layer(s) takes the data from the input layer and make something of it. This is where the calculations happen based on the input layer.\n",
    "\n",
    "### Output Layer: \n",
    "Outputs a vector of values that are used to make a prediction. The number of nodes within this layer depends on what type of problem we are trying to solve. For example, regression problems will have one node with a continuously variable number as the output. A binary classification problem will have two nodes, one yes and one no (this is where the sigmoid function might be used). The example on the video showed 10 nodes in the output layer as there were ten possible outputs we were predicting.\n",
    "\n",
    "Activation functions (like the sigmoid function) are used to transform the output into a contextually understandable format.\n",
    "\n",
    "### Neuron:\n",
    "Also called 'nodes', a neuron is a part of the NN that stores a value. Similar to the way that our brains function, these nodes pass on signals to the next node only when a certain threshold is reached. \n",
    "\n",
    "Neurons take an input value, multiply them by a specified weight, sums up all of the products and then passes the through an activation function which gives us the final value.\n",
    "\n",
    "### Weight:\n",
    "Is similar to the slope of a line: it modifies the input by multiplying it by a specified number, just like y = 3x. In my mind, I think of it as the importance of the input. The weight that is applied to the input data helps determine how accurate the model is. \n",
    "\n",
    "### Activation Function:\n",
    "Each node has an activation funciton. Nodes in the same layer typically have the same activation function. The activation function is what determines whether or not a node is activated or not. Within the output layer, activation functions make the output interpretable.\n",
    "\n",
    "### Node Map:\n",
    "Basically, it's a flow chart of how the neurons interact with each other. Usually they are color coded and help us understand the different architectures of different kinds of neural networks at a high level.\n",
    "\n",
    "### Perceptron:\n",
    "The simplest kind of neural network. Has an input layer and an output layer, but nothing else. The input layer can have many inputs and spits out an output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "#### Your Answer Here\n",
    "1. Input\n",
    "Data is collected in the input layer. This is the only place that the original data interacts with the neural network.\n",
    "\n",
    "2. Weights\n",
    "The input is then multiplied/modified by a given weight. These weights are added together to find the weighted sum.\n",
    "\n",
    "3. Bias\n",
    "The bias is then added to the weighted sum\n",
    "\n",
    "4. Activation Funcitons \n",
    "The activation function takes the values of the weighted sums and the bias in order to determine which neurons to activate in the following layer.\n",
    "\n",
    "5. Output\n",
    "Output is determined by the acivation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   0   0  1\n",
       "1   1   0  1\n",
       "2   0   1  1\n",
       "3   1   1  0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "# define a sigmoid function as the activation function\n",
    "\n",
    "import math \n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx*(1-sx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define inputs\n",
    "inputs = np.array(df) # why do we use the y column for our inputs?\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5049808 ],\n",
       "       [0.60592761],\n",
       "       [0.45748719]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize some random weights to begin\n",
    "np.random.seed(812)\n",
    "weights = np.random.random((3,1))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45748719],\n",
       "       [0.96246799],\n",
       "       [1.06341479],\n",
       "       [1.11090841]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the weighted sums of inputs and weights\n",
    "weighted_sum = np.dot(inputs, weights)\n",
    "weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6124179 ],\n",
       "       [0.72361567],\n",
       "       [0.74334258],\n",
       "       [0.75229843]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output the activated value for the end of 1 training epoch\n",
    "activated_outputs = sigmoid(weighted_sum)\n",
    "activated_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3875821 ],\n",
       "       [ 0.27638433],\n",
       "       [ 0.25665742],\n",
       "       [-0.75229843]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the difference of output and true values to calculate error\n",
    "correct_outputs = [[1],[1],[1],[0]]\n",
    "error = correct_outputs - activated_outputs\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09199735],\n",
       "       [ 0.05527577],\n",
       "       [ 0.04896623],\n",
       "       [-0.14018743]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use gradient descent to adjust weights\n",
    "adjustments = error * sigmoid_derivative(weighted_sum)\n",
    "adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42006914],\n",
       "       [0.51470641],\n",
       "       [0.65372654]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the new, more accurate weights\n",
    "weights = weights + np.dot(inputs.T, adjustments)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights after training\n",
      "[[-3.16683474]\n",
      " [-3.16679153]\n",
      " [ 9.7567521 ]]\n",
      "output after training\n",
      "[[0.9999421 ]\n",
      " [0.99862773]\n",
      " [0.99862779]\n",
      " [0.00177244]]\n"
     ]
    }
   ],
   "source": [
    "# update the weights 100,000 times\n",
    "\n",
    "for iteration in range(100000):\n",
    "    # weighted sum of inputs/weights\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    \n",
    "    # activate\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    # calculate error\n",
    "    error = correct_outputs - activated_output\n",
    "    \n",
    "    # use gradient descent to adjust weights\n",
    "    adjustments = error * sigmoid_derivative(weighted_sum)\n",
    "    \n",
    "    # update the weights\n",
    "    weights += np.dot(inputs.T, adjustments)\n",
    "    \n",
    "print(\"weights after training\")\n",
    "print(weights)\n",
    "\n",
    "print(\"output after training\")\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pregnancies',\n",
       " 'Glucose',\n",
       " 'BloodPressure',\n",
       " 'SkinThickness',\n",
       " 'Insulin',\n",
       " 'BMI',\n",
       " 'DiabetesPedigreeFunction',\n",
       " 'Age']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "feats = list(diabetes)[:-1]\n",
    "\n",
    "# X = ...\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03355237, 0.82762513, 0.40262844, 0.19572216, 0.        ,\n",
       "       0.18789327, 0.00350622, 0.27960308])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the data into a numpy array and exclude the outcomes column\n",
    "diabetes_array = np.array(diabetes[feats])\n",
    "\n",
    "# fit the normalizer\n",
    "transformer = Normalizer().fit(diabetes_array)\n",
    "\n",
    "# transform the data in the diabetes array to normalized values\n",
    "norm_diabetes = transformer.transform(diabetes_array)\n",
    "norm_diabetes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033552</td>\n",
       "      <td>0.827625</td>\n",
       "      <td>0.402628</td>\n",
       "      <td>0.195722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.279603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008424</td>\n",
       "      <td>0.716040</td>\n",
       "      <td>0.555984</td>\n",
       "      <td>0.244296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224079</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.261144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040398</td>\n",
       "      <td>0.924097</td>\n",
       "      <td>0.323181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.161591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006612</td>\n",
       "      <td>0.588467</td>\n",
       "      <td>0.436392</td>\n",
       "      <td>0.152076</td>\n",
       "      <td>0.621527</td>\n",
       "      <td>0.185797</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.138852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.596386</td>\n",
       "      <td>0.174127</td>\n",
       "      <td>0.152361</td>\n",
       "      <td>0.731335</td>\n",
       "      <td>0.187622</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.143655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0     0.033552  0.827625       0.402628       0.195722  0.000000  0.187893   \n",
       "1     0.008424  0.716040       0.555984       0.244296  0.000000  0.224079   \n",
       "2     0.040398  0.924097       0.323181       0.000000  0.000000  0.117658   \n",
       "3     0.006612  0.588467       0.436392       0.152076  0.621527  0.185797   \n",
       "4     0.000000  0.596386       0.174127       0.152361  0.731335  0.187622   \n",
       "\n",
       "   DiabetesPedigreeFunction       Age  Outcome  \n",
       "0                  0.003506  0.279603        1  \n",
       "1                  0.002957  0.261144        0  \n",
       "2                  0.003393  0.161591        1  \n",
       "3                  0.001104  0.138852        0  \n",
       "4                  0.009960  0.143655        1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(norm_diabetes, columns = feats)\n",
    "new_df['Outcome'] = diabetes['Outcome']\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "768\n",
      "768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03355237, 0.82762513, 0.40262844, ..., 0.00350622, 0.27960308,\n",
       "        1.        ],\n",
       "       [0.008424  , 0.71604034, 0.55598426, ..., 0.00295683, 0.26114412,\n",
       "        0.        ],\n",
       "       [0.04039768, 0.92409698, 0.32318146, ..., 0.00339341, 0.16159073,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.02691539, 0.65135243, 0.38758161, ..., 0.00131885, 0.16149234,\n",
       "        0.        ],\n",
       "       [0.00665306, 0.83828547, 0.39918356, ..., 0.00232192, 0.31269379,\n",
       "        1.        ],\n",
       "       [0.00791454, 0.73605211, 0.55401772, ..., 0.00249308, 0.18203439,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define inputs \n",
    "inputs = np.array(new_df)\n",
    "\n",
    "# correct outcomes or y\n",
    "correct_outcomes = np.array(new_df['Outcome'])\n",
    "print(len(correct_outcomes))\n",
    "print(len(new_df))\n",
    "print(len(inputs))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "##### Update this Class #####\n",
    "\n",
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, rate = 0.01, niter = 10):\n",
    "        self.niter = niter\n",
    "        self.rate = rate\n",
    "    \n",
    "    def sigmoid(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(x):\n",
    "        sx = sigmoid(x)\n",
    "        return sx*(1-sx)\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"calculate net input\"\"\"\n",
    "        return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        # if the predicted value is equal to or greater than .5, return 1. Otherwise return 0\n",
    "        return np.where(self.net_input(X) >= .5, 1, 0) \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "\n",
    "        # Randomly Initialize Weights\n",
    "        self.weight = np.random.random(1 + X.shape[1]) # what does this line of code do?\n",
    "        \n",
    "        # calculate misclassifications\n",
    "        self.errors = []\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            err = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                \n",
    "            # Weighted sum of inputs / weights\n",
    "                predictions = self.predict(xi)\n",
    "                delta_w = self.rate * (target - predictions) # predictions comes from the predict function defined below\n",
    "                \n",
    "                # activate\n",
    "                self.weight[1:] += delta_w * xi\n",
    "                \n",
    "                # update the weights\n",
    "                self.weight[0] += delta_w\n",
    "                \n",
    "                # calculate error\n",
    "                if delta_w != 0.0:\n",
    "                    err = err + 1\n",
    "                \n",
    "            self.errors.append(err)\n",
    "        return self\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pn = Perceptron(niter = 10)\n",
    "\n",
    "# fit the perceptron to the normalized diabetes df features\n",
    "pn.fit(inputs, correct_outcomes) # why is the prediction so eradic and random?\n",
    "plt.plot(range(1, len(pn.errors) + 1), pn.errors, marker = 'o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
